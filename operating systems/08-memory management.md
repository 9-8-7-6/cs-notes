# Memory Management
## Background
- Main memory and registers are the only storage CPU can access directly
- Multiple programs are brought into memory to improve performance and utilization
- A process can be moved between disk and memory using virtual memory

## Multistep Processing of a User Program

### Compile Time: compile or assemble
 
### Link Time: Link different library, include static linking

### Load Time: load into memory, include static loading

### Execution Time(run time): include dynamically loading and linking

![Multistep Processing of a User Program](https://media.geeksforgeeks.org/wp-content/uploads/20200531135539/1406-5.png)

## Address Binding
### Address binding - Compile Time
- Very fast
- MS-DOS .COM format binary
- Hard to move program, need to recompile and re-execute
![Address binding - Compile Time](https://miro.medium.com/v2/resize:fit:961/1*xYWARMqUFil-5c2fPzKj3w.png)

### Address binding - Load Time
- Compiler translate symbolic code into relocatable code(use base register)
- Still need to reload the code if need to move memory or swap in
![Address binding - Load Time](https://miro.medium.com/v2/resize:fit:1400/1*Vk-IIQq-mCgMSfLZmdp9AA.png)

### Address Binding - Execution Time

- Compiler translate symbolic code into logical-address(i.e. virtual-address) code
- MMU(hardware) is needed for this scheme
    - ![MMU](https://er.yuvayana.org/wp-content/uploads/sites/11/2020/05/Memory-Management-F10.png)
- Logical address(generated by *CPU*)
- Physical address(seen by memory module)
- Execution-time => logical address != physical address

![Address binding - Execution Time](
https://miro.medium.com/v2/resize:fit:1400/1*U4GXeIKBETi52HQMJWOvPQ.png)

## Dynamic/Static Loading & Linking
### Dynamic Loading
* A routine(function call) is loaded into memory when it is called
* Better memory-space utilization
    * unused routine is never loaded
    * useful when large amounts of code are infrequently used
### Static Linking
* Libraries are combined by the **loader** into the program in memory
* Different programs may each contain duplicated copies of the same library

## Swapping
* Move process between disk and memory
* A special disk area provides direct access for swapping, separated from the regular file system
* The speed is slow when moving, so it's important to calculate which data to be moved
### Why Swap a process:
- Free up memory
- Swap lower-priority process

| Binding time| Swap back memory space |
|---------------------|----------------------------|
| Compile-time binding| Must be the *same*         |
| Runtime binding     | Can be *different*         |

### Process to be swapped **must be idle**


## Memory Allocation
- Contiguous Allocation
    1. Fixed-partition allocation
        - Each process loads into one fixed-size space
        ![Fixed-partition allocation](https://media.geeksforgeeks.org/wp-content/uploads/20200515204405/fixedpartition.png)
    2. Variable-size partition 
        - Hole: block of contiguous free memory
        - Dynamic Storage Allocation algorithm
            - First-fit: allocate the **first** hole that fits
            - Best-fit: allocate the **smallest** hole that fit
            - Worst-fit allocate the **largest** hole that fit
        ![Variable-size partition](https://files.codingninjas.in/article_images/variable-size-partitioning-0-1641800237.webp)

### Fragmentation
> Left space unused when variable-size partition

* External fragmentation
    - Memory space left is not large enough to load the program, even if total free memory is bigger than the required
    - Occur in **variable-size allocation**

* Internal fragmentation
    - Memory space allocated is not fully utilized, leaving some part unused
    - Occurs in **fixed-partition allocation** when the allocated partition is larger than the actual process requirement

* Solution: compaction
    - Shuffle all the memory content to place all memory together into a large block in **execution time**

## Paging (Non-Contiguous Memory Allocation)

### Method
1. **Frames** – divide **physical memory** into fixed-size blocks.  
2. **Pages** – divide **logical address space (program)** into fixed-size blocks.  

> The number of **free pages** must at least equal the number of free **frames**.

---

### Benefits
1. Avoid **external fragmentation**.  
2. Reduce **internal fragmentation** by using smaller page sizes.  
   - Common page sizes: **4KB / 8KB**  
   - Modern systems may support **larger pages**.

---

### Page Table

> **Purpose:** Translate logical addresses into physical addresses.

A **logical address** is composed of:

- **Page number (p):**  
  - Index into the page table which provides the base address of each page in physical memory.  
  - If the page number uses **N bits**, then:  
    - A process can have at most **2ⁿ pages**.  
    - Maximum allocatable memory = **2ⁿ × page size**.

- **Page offset (d):** Position within the page.  

**Physical address = page base address + page offset**

---

### Example

```yaml
Virtual address = 0x1234

0x1234 (HEX) = 0001 0010 0011 0100 (Binary, 16 bits)

Page number = 0001 (high 4 bits) = 1
Page offset = 0010 0011 0100 (low 12 bits) = 0x234

=> Address belongs to logical page 1, offset 0x234
```

### Implementation of Page Table

#### Page-Table Base Register (PTBR)
- Located in the **Memory Management Unit (MMU)**.  
- Contains the **physical memory address** of the page table.  
- Its value is stored in the **Process Control Block (PCB)** of each process.

---

#### Two-Step Memory Access

**Steps:**
1. Access the **page table** to get the **frame number**.  
2. Access the **physical memory** using the **frame number + offset**.  

**Characteristics:**
- Requires **two memory accesses**, which makes it **slower**.  
- Speed can be improved using a **Translation Lookaside Buffer (TLB)**.

---

#### Translation Lookaside Buffer (TLB)

**Overview:**
- A form of **associative memory**, accessed **by content**, not by address.  
- Implemented in **MMU hardware** for constant-time **O(1)** lookups.  
- Has **limited size** due to hardware constraints.

**Behavior:**
- May be **flushed** after a **context switch**.  
- Some TLBs include a **Process ID (PID)** field to distinguish entries from different processes, avoiding unnecessary flushing.

#### Maintained by the **OS** for each process.  

#### Calculate Effective Memory-Access Time

```yaml
- 20 ns for TLB search
- 100ns for memory access

Effective Memory-Access Time(EMAT)
- if 70% hit-ratio
    EMAT = 0.7 * (20 + 100) + (1 - 0.7) * (20 + 100 + 100) = 150 ns

if 98% TLB hit-ratio
    EMAT = 0.98 * 120 + 0.02 * 220 = 122 ns
```

![Page Table Implementation](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRH6ttm1sus7BGQO2R_FcEjEta8s0dMDEdpDw&s)

---

#### Memory Protection
- Each **page** has associated **protection bits** stored in the page table.
- These bits define allowed operations:
  - **Read**, **Write**, **Execute** permissions.
- **Valid–Invalid bit**:
  - **Valid (1):** Page is in physical memory and accessible.
  - **Invalid (0):** Page is not accessible (either not allocated, swapped out, or reserved for kernel/virtual memory).

---

#### Shared Pages

> **Idea:** Map the same physical page frame into multiple processes’ address spaces to save memory.

- **Code sharing:**  
  Multiple processes can share common **text/code segments**.
- **Requirement:**  
  Must be **reentrant (pure)** code — execution does not depend on local state or self-modifying behavior.
- **Protection:**  
  Only one copy of **read-only** shared code is stored in physical memory.
- **Copy-on-Write (COW):**  
  After a `fork()`, parent and child **share pages** until one modifies them;  
  on first write, the OS **duplicates** the page, maintaining separate copies.

---

#### Solutions to Large Page Tables

> For large logical address spaces, page tables can be huge.  
> These schemes reduce memory usage or lookup cost.

1. **Hierarchical Paging**
   - Divide the page table into multiple smaller tables.
   - Example: Two-level paging —  
     logical address split into:
     - 10-bit **outer index**
     - 10-bit **inner index**
     - 12-bit **page offset**
   - The outer table points to inner tables, reducing unused memory.
   - Trade-off: More lookups per access (multiple memory references).

   ![Two-Level Page Table](https://i.sstatic.net/Iz7Ti.png)

2. **Hashed Page Table**
   - The **virtual page number** is hashed into a bucket.
   - Each bucket contains entries (virtual page → frame number).
   - Pages are allocated **on demand**.
   - Efficient for large, sparse address spaces but may waste space in pointers.

   ![Hash Page Tables](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT9I21E-wo71VQhm4XM4XqkZ1FBD-_4Pi-QdA&s)

3. **Inverted Page Table**
   - One entry per **physical frame**, not per virtual page.
   - Each entry stores `(PID, virtual page number)`.
   - Greatly reduces memory used for tables.
   - Harder to support **shared memory** because lookup requires both PID and VPN.

   ![Inverted Page Table](https://media.geeksforgeeks.org/wp-content/uploads/33-6.png)

---

#### Quick Comparison

| Scheme                  | Memory Overhead                    | Miss Handling Cost          | Best For                          |
|--------------------------|------------------------------------|-----------------------------|-----------------------------------|
| Multi-Level Paging       | Low for sparse spaces (on-demand)  | Multiple level walks        | General-purpose OS, x86-64        |
| Hashed Page Tables       | Proportional to used pages         | Hash + bucket scan          | Large, sparse 64-bit spaces       |
| Inverted Page Table      | Proportional to **physical frames**| Hash/probe in IPT           | Systems minimizing table memory   |

---

## Segmentation

> Divide process logical address space into **variable-size segments**  
> (e.g., code, stack, heap, global data).

- **Non-continuous Allocation**
  - **Paging:** Fixed-size blocks.
- **Continuous Allocation**
  - **Segmentation:** Variable-size blocks.

- **Logical Address Format:** `(segment number, offset)`
  - Must satisfy `0 ≤ offset < limit(segment)`.

---

### Segment Table (Per Process)
Each entry contains:
- **Base:** Starting physical address of the segment.
- **Limit:** Length (in bytes) of the segment.
- **Protection bits:** Read/Write/Execute permissions.

**Address Translation:**
> If `offset < limit`: **physical address = base + offset**  
else **trap (segmentation fault)**.

### Address Translation Comparison
- **Segment:**
    - Table entry: (base, limit, flags)
    - Segment base address could be **arbitrary**
    - The length of limit is the same as **physical memory size**
- **Page:**
    - Table entry: (frame base address)
    - Frame base address = frame number * page size
    - The length of offset is the same as **page size**

## Segmentation with Paging
- Apply segmentation in logic address space
- Apply paging in physical address space

- ![Segmentation with Paging](https://www.gatevidyalay.com/wp-content/uploads/2018/11/Segmented-Paging-Translating-Logical-Address-into-Physical-Address-Diagram.png)